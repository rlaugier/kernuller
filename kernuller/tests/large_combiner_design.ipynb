{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and pruning of large combiner matrices\n",
    "With, kernuller, it is easy to build large matrices for combiners of many inputs (within the bounds of your RAM).\n",
    "Here, we show how to identify the amount of observations provided by those combiners, and some tools to reduce the number of outputs to its minimum, which is still a challenge.\n",
    "## Evaluation of the number of independent outputs\n",
    "The first step is to be able to evaluate the number of independant outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "#import kernuller_class as kernuller\n",
    "import kernuller\n",
    "import astropy.coordinates\n",
    "import astropy.units as u\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use set up a number of random binary parameters that must cover the input (observed scene parameter space). This number should be larger than the number of outputs of the combiners tested. (Using random numbers helps making sure we do not fall into symmetry or spacial frequency tropes, but the analysis should also work with a grid of source positions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrands = 400\n",
    "randrhos = 0.5+ 40*np.random.rand(nrands)\n",
    "randthetas = 360*np.random.rand(nrands)\n",
    "randconts = 400*np.ones(nrands)\n",
    "params = np.array([[randrhos[i], randthetas[i], randconts[i]] for i in range(randrhos.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a specific `CHARA2` array that has 7 apertures in a non-redundant configuration.\n",
    "\n",
    "For each size of array (3 to 7 apertures), we build a kernuller object, then use the `get_rank()` methods with the array of test parameters, once for the nulls, and once for the kernels, to get the number of dimensions of both the set of nulls and the set of kernel nulls.\n",
    "\n",
    "The `get_rank()` method computes the combiner's outputs (or kernel-outputs) for the whole set of inputs. These outputs constitute a family of outputs. The number of independent outputs is the number of independent vectors in this family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARA2 = np.vstack((kernuller.CHARA, np.array([30.,30.])))\n",
    "nas = np.arange(3,8)\n",
    "nullranks = []\n",
    "kernranks = []\n",
    "sizes = []\n",
    "for i in nas:\n",
    "    print(\"Working on a %d -input combiner\"%(i))\n",
    "    kernuller.expected_numbers(i)\n",
    "    print(\"=====================================================\")\n",
    "    mykernuller = kernuller.kernuller(CHARA2[:i], 3.6e-6)\n",
    "    mykernuller.build_procedural_model(verbose=False)\n",
    "    sizes.append(mykernuller.Np.shape[0])\n",
    "    anullrank = mykernuller.get_rank(params=params, mode=\"\")\n",
    "    nullranks.append(anullrank)\n",
    "    akernelrank = mykernuller.get_rank(params=params, mode=\"kernels\")\n",
    "    kernranks.append(akernelrank)\n",
    "    print(\"Found a null rank of %d\"%(anullrank))\n",
    "    print(\"Found a kernel rank of %d\"%(akernelrank))\n",
    "    print(\"=====================================================\")\n",
    "sizes = np.array(sizes)\n",
    "nullranks = np.array(nullranks)\n",
    "kernranks = np.array(kernranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's make a pretty plot of our results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thnas = np.arange(3,18)\n",
    "fig = plt.figure(figsize=(7.5, 5.5))\n",
    "plt.plot(nas[:-2], sizes[:-2],marker=\"X\",\n",
    "         linestyle=\"None\",markersize=14, label=\"Number of nulls\")\n",
    "\n",
    "plt.plot(thnas, (thnas-1)*(thnas-2), \"k--\", label=\"Expected numbers\")\n",
    "plt.plot(nas, nullranks,marker=\"P\",\n",
    "         linestyle=\"None\",markersize=10, label=\"Number of independent nulls\")\n",
    "plt.plot(thnas, 1/2*(thnas-1)*(thnas-2), \"k--\")\n",
    "plt.plot(nas, kernranks,marker=\"o\",\n",
    "         linestyle=\"None\",markersize=10, label=\"Number of independent kernel nulls\")\n",
    "#plt.plot(9, 8, color=\"C1\", marker=\"s\", label=\"9 apertures cascaded nulls\")\n",
    "#plt.plot(9, 4, color=\"C2\", marker=\"s\", label=\"9 apertures cascaded kernel nulls\")\n",
    "extranas = nas[-2:]\n",
    "extrasizes = sizes[-2:]\n",
    "plt.plot(extranas, 70*np.ones_like(extranas), marker=\"X\",color=\"C0\",\n",
    "         markersize=12, linestyle=\"None\")\n",
    "for anextranas, anextrasize  in zip(extranas, extrasizes):\n",
    "    print(anextranas,anextrasize)\n",
    "    plt.arrow(anextranas, 70, 0, 5, head_width=0.2, head_length=5, color=\"C0\")\n",
    "    plt.text(anextranas, 70+2, str(anextrasize),color=\"C0\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylim(0, 80)\n",
    "plt.xlim(2, 14)\n",
    "plt.xticks(ticks=np.arange(2,15))\n",
    "plt.xlabel(r\"Number of inputs $n_a$\")\n",
    "plt.grid()\n",
    "#plt.title(\"Growth of kernel nullers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building reduced combiners\n",
    "Now the possibility to reduce the combiners to those numbers is an entirely different matter. The delicate part is to make sure that the matrix we build ( by adding or removing rows ) remains the matrix of a lossless combiner.\n",
    "\n",
    "The matrices of lossless combiners are semi-unitary to the left, meaning that that their conjugate-transpose is their left-inverse:\n",
    "$$\\mathbf{M}^H\\mathbf{M} = \\mathbf{I}.$$\n",
    "This also means (equivalent) that all their singular values are ones.\n",
    "\n",
    "\n",
    "The way we have used is implemented in the algorithm offerred in `generative_random_pruning()`.\n",
    "\n",
    "The algorithm will try random ways to build a matrix, recording the steps it took (the recipe), and saving this recipe if the result is both lossless and complete (gives full rank *kernels*).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statlocs = kernuller.CHARA\n",
    "mykernuller = kernuller.kernuller(statlocs,3.6e-6)\n",
    "mykernuller.build_procedural_model(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One of the problems with this approach that inside the function, there is no good way to stop the search yet keep the recipes found...\n",
    "For the 6T combination, you have to run it for around 2000 iterations if you want to be relatively sure to find something (10-15 minutes on a decent workstation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices, recipes = kernuller.generative_random_pruning(mykernuller.Ms, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We found %d matrices, here is one:\"%(len(matrices)))\n",
    "matrices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to store those matrices is by using `np.save()`. However, numpy will pickle it, so when loading them, you have to make sure to allow pickle: `np.load(\"my/matrix.npy\", allow_pickle=True)`\n",
    "\n",
    "The legacy way to store the matrices is to store the recipe (which looks like that):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix can then be recovered by sending the recipe to to a method that follows the same steps but in a deterministic manner following the recipe.\n",
    "\n",
    "For this reason, it is super important that generative_random_pruning() and generative_from_recipe() remain in sync. When changing one, the other must be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernuller.generative_from_recipe(mykernuller.Ms, recipes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
